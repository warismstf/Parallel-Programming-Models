#include <iostream>
#include <cuda_runtime.h>

#define N 1000

using namespace std;

__global__ void matrix_multiply(int* A, int* B, int* C) {
  int i = blockIdx.x * blockDim.x + threadIdx.x;
  int j = blockIdx.y * blockDim.y + threadIdx.y;

  if (i < N && j < N) {
    int sum = 0;
    for (int k = 0; k < N; k++) {
      sum += A[i * N + k] * B[k * N + j];
    }
    C[i * N + j] = sum;
  }
}

int main() {
  int A[N][N], B[N][N], C[N][N];
  int* dev_A, *dev_B, *dev_C;

  // Allocate device memory
  cudaMalloc((void**)&dev_A, N * N * sizeof(int));
  cudaMalloc((void**)&dev_B, N * N * sizeof(int));
  cudaMalloc((void**)&dev_C, N * N * sizeof(int));

  // Initialize matrices A and B
  for (int i = 0; i < N; i++) {
    for (int j = 0; j < N; j++) {
      A[i][j] = i + j;
      B[i][j] = i - j;
      C[i][j] = 0;
    }
  }

  // Copy data from host to device
  cudaMemcpy(dev_A, A, N * N * sizeof(int), cudaMemcpyHostToDevice);
  cudaMemcpy(dev_B, B, N * N * sizeof(int), cudaMemcpyHostToDevice);

  // Set grid and block sizes
  dim3 threadsPerBlock(16, 16);
  dim3 numBlocks(N / threadsPerBlock.x, N / threadsPerBlock.y);

  // Matrix multiplication using CUDA
  matrix_multiply<<<numBlocks, threadsPerBlock>>>(dev_A, dev_B, dev_C);

  // Copy data from device to host
  cudaMemcpy(C, dev_C, N * N * sizeof(int), cudaMemcpyDeviceToHost);

  // Print the result matrix C
  for (int i = 0; i < N; i++) {
    for (int j = 0; j < N; j++) {
      cout << C[i][j] << " ";
    }
    cout << endl;
  }

  // Free device memory
  cudaFree(dev_A);
  cudaFree(dev_B);
  cudaFree(dev_C);

  return 0;
}
